{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 607b025] Ajustes\n",
      " 2 files changed, 79 insertions(+), 63 deletions(-)\n",
      "Counting objects: 4, done.\n",
      "Delta compression using up to 32 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (4/4), 1.01 KiB | 0 bytes/s, done.\n",
      "Total 4 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/Jonlenes/MscProject.git\n",
      "   5be19b8..607b025  master -> master\n",
      "Branch master set up to track remote branch master from origin.\n"
     ]
    }
   ],
   "source": [
    "# !git init\n",
    "# !git add .\n",
    "# !git remote add origin https://github.com/Jonlenes/MscProject.git\n",
    "\n",
    "!git add .\n",
    "!git commit -m \"Ajustes\"\n",
    "!git push -u origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klYh798plIIq"
   },
   "source": [
    "###Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prNFyJCiMncf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  6 17:41:15 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   34C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   34C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   36C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhxSbOu7kcCw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, ZeroPadding2D, Activation\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model\n",
    "\n",
    "# import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import abc\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJ4gPobtJOU9"
   },
   "outputs": [],
   "source": [
    "class IDataset(abc.ABC):\n",
    "    @classmethod\n",
    "    def __init__(self, height=28, width=28, channel=1):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "        self.index = 0\n",
    "        self.load_data(self)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def load_data(self): raise NotImplementedError\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def __len__(self): \n",
    "        return len(self.x_train)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def iteration_to_begin(self):\n",
    "        self.index = 0\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def nexts(self, lot_size):\n",
    "        last_index = self.index + lot_size\n",
    "        if last_index >= self.__len__():\n",
    "            if self.index < self.__len__():\n",
    "                last_index = self.__len__() - 1\n",
    "            else:\n",
    "                raise Exception('EOF!')\n",
    "        \n",
    "        x = self.x_train[self.index:last_index]\n",
    "        self.index += lot_size\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def has_next(self):\n",
    "        return self.index < self.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YN3-OZ83lNTR"
   },
   "outputs": [],
   "source": [
    "class MINISTDataset(IDataset):\n",
    "    def __init__(self):\n",
    "        super(MINISTDataset, self).__init__()\n",
    "    \n",
    "    def load_data(self):\n",
    "        print(\"Dowloand/Extract MINIST\")\n",
    "        (x_train, _), (_, _) = mnist.load_data()\n",
    "        x_train = x_train / 255.0\n",
    "        x_train = x_train.reshape(-1, self.height, self.width, self.channel)\n",
    "        self.x_train = x_train\n",
    "        print(\"Finished: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ii5H1UL1Lh_M"
   },
   "outputs": [],
   "source": [
    "class NoiseDataset(abc.ABC):\n",
    "    def __init__(self):\n",
    "        super(NoiseDataset, self).__init__()\n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def __len__(self): \n",
    "        return np.int64(99999999999)\n",
    "        \n",
    "    \n",
    "    def nexts(self, lot_size):\n",
    "        return np.random.uniform(-1.0, 1.0, size=[lot_size, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJrhzoECFfiM"
   },
   "outputs": [],
   "source": [
    "class IDCGANModel(abc.ABC):\n",
    "    @classmethod\n",
    "    def __init__(self):\n",
    "        self._discriminator = self._build_new_discriminator(self)\n",
    "        self._generator = self._build_new_generator(self)\n",
    "        \n",
    "        self._adversarial = None\n",
    "        \n",
    "        \n",
    "    @abstractmethod\n",
    "    def _build_new_discriminator(self, input_shape): raise NotImplementedError\n",
    "        \n",
    "        \n",
    "    @abstractmethod\n",
    "    def _build_new_generator(self): raise NotImplementedError\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def discriminator(self): return self._discriminator\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def generator(self): return self._generator\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def adversarial(self): return self._adversarial\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def save_discriminator(self, path_save): self._discriminator.save(path_save)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def load_discriminator(self, path_save): self._discriminator = load_model(path_save)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def save_generator(self, path_save): self._generator.save(path_save)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def load_generator(self, path_save): self._generator = load_model(path_save)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def compile_discriminator(self, optimizer=RMSprop(lr=0.0002, decay=6e-8), loss='binary_crossentropy', metrics=['accuracy']):\n",
    "        self._discriminator.trainable = True\n",
    "        self._discriminator.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        return self._discriminator\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def compile_adversarial(self, optimizer=RMSprop(lr=0.0001, decay=3e-8), loss='binary_crossentropy', metrics=None):\n",
    "        self._discriminator.trainable = False\n",
    "        self._adversarial = Sequencial()\n",
    "        self._adversarial.add(self._generator)\n",
    "        self._adversarial.add(self._discriminator)\n",
    "        self._adversarial.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        return self._adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87YNF6Uqnosv"
   },
   "outputs": [],
   "source": [
    "class DCGANModel(IDCGANModel):\n",
    "    def _build_new_discriminator(self, input_shape=(28, 28, 1)):\n",
    "        \n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        #model.summary()\n",
    "        \n",
    "        return model\n",
    "      \n",
    "    \n",
    "    def _build_new_generator(self):\n",
    "\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        model.add(BatchNormalization(momentum=0.9))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Reshape((dim, dim, depth)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.9))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.9))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.9))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        model.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        #model.summary()\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9s9NJY2Uq4b0"
   },
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    \n",
    "    def elapsed_time(self):\n",
    "        sec = time.time() - self.start_time\n",
    "        if sec < 60:\n",
    "            return str(round(sec, 2)) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(round(sec / 60, 2)) + \" min\"\n",
    "        else:\n",
    "            return str(round(sec / (60 * 60), 2)) + \" hr\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnC1aLLcrId1"
   },
   "outputs": [],
   "source": [
    "class GANTrainer:\n",
    "    def __init__(self, GANModel, dataset_real, dataset_generator, preview_epoch=True, \n",
    "                 save_epoch_interval=10, num_imgs_save=25, make_grid=True, save_path=\"./result/\"):\n",
    "        \n",
    "        self.dataset_real = dataset_real\n",
    "        self.dataset_generator = dataset_generator\n",
    "        self.save_epoch_interval = save_epoch_interval\n",
    "        self.num_imgs_save = num_imgs_save\n",
    "        self.make_grid = make_grid\n",
    "        self.save_path = save_path\n",
    "        self.preview_epoch = preview_epoch\n",
    "        self.GANModel = GANModel\n",
    "\n",
    "\n",
    "    def fit(self, epochs=50, batch_size=32):\n",
    "        \n",
    "        print(\"Starting train for %d epochs\" % epochs)\n",
    "        timer = Timer()\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            timer.start()\n",
    "            while self.dataset_real.has_next():\n",
    "                #-----------------DISCRIMINATOR-----------------#\n",
    "                # Dados do conjunto de treinamento real\n",
    "                x_train_real = self.dataset_real.nexts(batch_size)\n",
    "                y_train_real = np.ones((len(x_train_real), 1))\n",
    "\n",
    "                # Dados fakes gerados pelo Gerador\n",
    "                x_train_fake = self.GANModel.generator().predict( self.dataset_generator.nexts(batch_size) )\n",
    "                y_train_fake = np.zeros((batch_size, 1))\n",
    "                \n",
    "                # Treinando por um batch\n",
    "                d_loss_real = self.GANModel.discriminator().train_on_batch(x_train_real, y_train_real)\n",
    "                d_loss_fake = self.GANModel.discriminator().train_on_batch(x_train_fake, y_train_fake)\n",
    "                \n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                #-----------------DISCRIMINATOR-----------------#\n",
    "\n",
    "\n",
    "                #-------------------GENERATOR-------------------#\n",
    "                x = self.dataset_generator.nexts(batch_size)\n",
    "                y = np.ones((len(x), 1)) # Dizer que é real\n",
    "\n",
    "                a_loss = self.GANModel.adversarial().train_on_batch(x, y)\n",
    "                #-------------------GENERATOR-------------------#\n",
    "\n",
    "            self.dataset_real.iteration_to_begin()\n",
    "                \n",
    "            # Model evolution\n",
    "            print(\"Epoch %02d - Time %s  - [D loss: %.2f, acc.: %.2f%%] [G loss: %.2f]\" % (epoch, timer.elapsed_time(), d_loss[0], 100 * d_loss[1], a_loss))\n",
    "\n",
    "            # Saving sample\n",
    "            self.show_save_samples(epoch, epoch % self.save_epoch_interval==0)\n",
    "\n",
    "                        \n",
    "    def show_save_samples(self, epoch, save):\n",
    "        self._make_img_grid(epoch, save and self.make_grid)\n",
    "        if save and not self.make_grid:\n",
    "            self._save_genereted_image(epoch)\n",
    "      \n",
    "                            \n",
    "    def _make_img_grid(self, epoch, save=False):\n",
    "\n",
    "        r = c = int(np.sqrt(self.num_imgs_save))\n",
    "\n",
    "        gen_imgs = self.GANModel.generator().predict( self.dataset_generator.nexts(r * c) )\n",
    "        #(???) Esse normalização é necessária? gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                count += 1\n",
    "\n",
    "        if save:\n",
    "            fig.savefig(self.save_path + \"result_epoch_%d.png\" % (epoch))\n",
    "            print(\"Image grid result save.\")\n",
    "\n",
    "        if self.preview_epoch:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1007
    },
    "colab_type": "code",
    "id": "yob7T7Lvzal5",
    "outputId": "af7b74b6-bc82-484a-b318-1a9f23da86d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dowloand/Extract MINIST\n",
      "Finished:  (60000, 28, 28, 1)\n",
      "Starting train for 10 epochs\n"
     ]
    }
   ],
   "source": [
    "model = DCGANModel_1()\n",
    "\n",
    "model.compile_discriminator()\n",
    "model.compile_adversarial()\n",
    "\n",
    "trainer = GANTrainer(model, MINISTDataset(), NoiseDataset(), save_epoch_interval=10, preview_epoch=True)\n",
    "trainer.fit(epochs=10)\n",
    "\n",
    "# model.save_discriminator('result/model_minist_dis_v1.h5')\n",
    "# model.save_generator('result/model_minist_gen_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GANs",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
