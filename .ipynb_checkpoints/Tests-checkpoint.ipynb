{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_generator(noise_shape=(100,)):\n",
    "    input = Input(noise_shape)\n",
    "    x = Dense(128 * 8 * 8, activation=\"relu\")(input)\n",
    "    x = Reshape((8, 8, 128))(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "    out = Activation(\"tanh\")(x)\n",
    "    model = Model(input, out)\n",
    "    print(\"-- Generator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    input = Input(img_shape)\n",
    "    x =Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = (LeakyReLU(alpha=0.2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(input, out)\n",
    "    print(\"-- Discriminator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    return X_train\n",
    "\n",
    "\n",
    "def train(generator, discriminator, combined, epochs=2000, batch_size=128, save_interval=50):\n",
    "\n",
    "    X_train = load_data()\n",
    "\n",
    "    num_examples = X_train.shape[0]\n",
    "    num_batches = int(num_examples / float(batch_size))\n",
    "    print('Number of examples: ', num_examples)\n",
    "    print('Number of Batches: ', num_batches)\n",
    "    print('Number of epochs: ', epochs)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        for batch in range(num_batches):\n",
    "            print(\"Batch: \" + str(batch) + \"/\" + str(num_batches))\n",
    "\n",
    "            # noise images for the batch\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "            fake_images = generator.predict(noise)\n",
    "            fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "            # real images for batch\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            real_images = X_train[idx]\n",
    "            real_labels = np.ones((half_batch, 1))\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            # Train the generator\n",
    "            g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Plot the progress\n",
    "            print(\"Epoch %d Batch %d/%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
    "                  (epoch, batch, num_batches, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                save_imgs(generator, epoch, batch)\n",
    "\n",
    "\n",
    "def save_imgs(generator, epoch, batch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/cifar10_%d_%d.png\" % (epoch, batch))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def build_models():\n",
    "\n",
    "    gen_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "    disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "    discriminator = build_discriminator(img_shape=(32, 32, 3))\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                               optimizer=disc_optimizer,\n",
    "                               metrics=['accuracy'])\n",
    "\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
    "\n",
    "    z = Input(shape=(100,))\n",
    "    img = generator(z)\n",
    "    discriminator.trainable = False\n",
    "    real = discriminator(img)\n",
    "    combined = Model(z, real)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
    "    return generator, discriminator, combined\n",
    "\n",
    "\n",
    "def main():\n",
    "    generator, discriminator, combined = build_models()\n",
    "\n",
    "    train(generator, discriminator, combined,\n",
    "          epochs=100, batch_size=32, save_interval=1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "file: ACGAN - CIFAR10.py\n",
    "author: Luke\n",
    "de\n",
    "Oliveira(lukedeo @ vaitech.io)\n",
    "contributor: KnightTuYa(398225157 @ qq.com)\n",
    "Consult\n",
    "https: // github.com / lukedeo / keras - acgan\n",
    "for MNIST version!\n",
    "Consult\n",
    "https: // github.com / soumith / ganhacks\n",
    "for GAN trick!\n",
    "I directly use Minibatch Layer Code from:\n",
    "https://github.com/forcecore/Keras-GAN-Animeface-Character\n",
    "Thanks for the great work!\n",
    "I am still not satisfied with the generated images yet, Any suggestion is welcomed!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "from PIL import Image\n",
    "from six.moves import range\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2DTranspose, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from Minibatch import MinibatchDiscrimination\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.noise import GaussianNoise\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "class_num = 10\n",
    "K.set_image_dim_ordering('th')\n",
    "path = \"images\"  # The path to store the generated images\n",
    "load_weight = False\n",
    "# Set True if you need to reload weight\n",
    "load_epoch = 100  # Decide which epoch to reload weight, please check your file name\n",
    "\n",
    "def build_generator(latent_size):\n",
    "    # we will map a pair of (z, L), where z is a latent vector and L is a\n",
    "    # label drawn from P_c, to image space (..., 3, 32, 32)\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Dense(384 * 4 * 4, input_dim=latent_size, activation='relu',\n",
    "                  kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(Reshape((384, 4, 4)))\n",
    "\n",
    "    cnn.add(Conv2DTranspose(192, kernel_size=5, strides=2, padding='same', activation='relu',\n",
    "                            kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "\n",
    "    cnn.add(Conv2DTranspose(96, kernel_size=5, strides=2, padding='same', activation='relu',\n",
    "                            kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "\n",
    "    cnn.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh',\n",
    "                            kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "\n",
    "    # this is the z space commonly refered to in GAN papers\n",
    "    latent = Input(shape=(latent_size,))\n",
    "\n",
    "    # this will be our label\n",
    "    image_class = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    # 10 classes in CIFAR-10\n",
    "    cls = Flatten()(Embedding(10, latent_size,\n",
    "                              embeddings_initializer='glorot_normal')(image_class))\n",
    "\n",
    "    # hadamard product between z-space and a class conditional embedding\n",
    "    h = layers.multiply([latent, cls])\n",
    "\n",
    "    fake_image = cnn(h)\n",
    "\n",
    "    return Model([latent, image_class], fake_image)\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    # build a relatively standard conv net, with LeakyReLUs as suggested in\n",
    "    # the reference paper\n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(GaussianNoise(0.05, input_shape=(3, 32, 32)))  # Add this layer to prevent D from overfitting!\n",
    "\n",
    "    cnn.add(Conv2D(16, kernel_size=3, strides=2, padding='same', kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Conv2D(32, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Conv2D(64, kernel_size=3, strides=2, padding='same', kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Conv2D(128, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Conv2D(256, kernel_size=3, strides=2, padding='same', kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Conv2D(512, kernel_size=3, strides=1, padding='same',kernel_initializer='glorot_normal', bias_initializer='Zeros'))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(LeakyReLU(alpha=0.2))\n",
    "    cnn.add(Dropout(0.5))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    cnn.add(MinibatchDiscrimination(50, 30))\n",
    "\n",
    "    image = Input(shape=(3, 32, 32))\n",
    "\n",
    "    features = cnn(image)\n",
    "\n",
    "    # first output (name=generation) is whether or not the discriminator\n",
    "    # thinks the image that is being shown is fake, and the second output\n",
    "    # (name=auxiliary) is the class that the discriminator thinks the image\n",
    "    # belongs to.\n",
    "    \n",
    "    # Saida para que indica se a imagem é fake ou não\n",
    "    fake = Dense(1, activation='sigmoid', name='generation', kernel_initializer='glorot_normal', bias_initializer='Zeros')(features)\n",
    "    # Qual classe pertence a imagem?\n",
    "    aux = Dense(class_num, activation='softmax', name='auxiliary', kernel_initializer='glorot_normal', bias_initializer='Zeros')(features)\n",
    "\n",
    "    return Model(image, [fake, aux])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # batch and latent size taken from the paper\n",
    "    nb_epochs = 1000\n",
    "    batch_size = 100\n",
    "    latent_size = 110\n",
    "\n",
    "    # Adam parameters suggested in https://arxiv.org/abs/1511.06434\n",
    "    adam_lr = 0.0002\n",
    "    adam_beta_1 = 0.5\n",
    "\n",
    "    # build the discriminator, Choose Adam as optimizer according to GANHACK\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(\n",
    "        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "    generator = build_generator(latent_size)\n",
    "\n",
    "    latent = Input(shape=(latent_size,))\n",
    "    image_class = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    # get a fake image\n",
    "    fake = generator([latent, image_class])\n",
    "\n",
    "    # we only want to be able to train generator for the combined model\n",
    "    discriminator.trainable = False\n",
    "    fake, aux = discriminator(fake)\n",
    "    combined = Model([latent, image_class], [fake, aux])\n",
    "\n",
    "    combined.compile(\n",
    "        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "    nb_train, nb_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    train_history = defaultdict(list)\n",
    "    test_history = defaultdict(list)\n",
    "\n",
    "    if load_weight:\n",
    "        generator.load_weights('params_generator_epoch_{0:03d}.hdf5'.format(load_epoch))\n",
    "        discriminator.load_weights('params_discriminator_epoch_{0:03d}.hdf5'.format(load_epoch))\n",
    "    else:\n",
    "        load_epoch = 0\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        print('Epoch {} of {}'.format(load_epoch + 1, nb_epochs))\n",
    "        load_epoch += 1\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        progress_bar = Progbar(target=nb_batches)\n",
    "\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for index in range(nb_batches):\n",
    "            progress_bar.update(index)\n",
    "            # generate a new batch of noise\n",
    "            noise = np.random.normal(0, 0.5, (batch_size, latent_size))\n",
    "\n",
    "            # get a batch of real images\n",
    "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "            label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            # sample some labels from p_c\n",
    "            sampled_labels = np.random.randint(0, class_num, batch_size)\n",
    "\n",
    "            # generate a batch of fake images, using the generated labels as a\n",
    "            # conditioner. We reshape the sampled labels to be\n",
    "            # (batch_size, 1) so that we can feed them into the embedding\n",
    "            # layer as a length one sequence\n",
    "            generated_images = generator.predict(\n",
    "                [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n",
    "\n",
    "            disc_real_weight = [np.ones(batch_size), 2 * np.ones(batch_size)]\n",
    "            disc_fake_weight = [np.ones(batch_size), np.zeros(batch_size)]\n",
    "\n",
    "            # According to GANHACK, We training our ACGAN-CIFAR10 in Real->D, Fake->D,\n",
    "            # Noise->G, rather than traditional method: [Real, Fake]->D, Noise->G, actully,\n",
    "            # it really make sense!\n",
    "\n",
    "            for train_ix in range(3):\n",
    "                if index % 30 != 0:\n",
    "                    X_real = image_batch\n",
    "                    # Label Soomthing\n",
    "                    y_real = np.random.uniform(0.7, 1.2, size=(batch_size,))\n",
    "                    aux_y1 = label_batch.reshape(-1, )\n",
    "                    epoch_disc_loss.append(discriminator.train_on_batch(X_real, [y_real, aux_y1]))\n",
    "                    # Label Soomthing\n",
    "                    X_fake = generated_images\n",
    "                    y_fake = np.random.uniform(0.0, 0.3, size=(batch_size,))\n",
    "                    aux_y2 = sampled_labels\n",
    "\n",
    "                    # see if the discriminator can figure itself out...\n",
    "                    epoch_disc_loss.append(discriminator.train_on_batch(X_fake, [y_fake, aux_y2]))\n",
    "                else:\n",
    "                    # make the labels the noisy for the discriminator: occasionally flip the labels\n",
    "                    # when training the discriminator\n",
    "                    X_real = image_batch\n",
    "                    y_real = np.random.uniform(0.0, 0.3, size=(batch_size,))\n",
    "                    aux_y1 = label_batch.reshape(-1, )\n",
    "\n",
    "                    epoch_disc_loss.append(discriminator.train_on_batch(X_real, [y_real, aux_y1]))\n",
    "                    # Label Soomthing\n",
    "                    X_fake = generated_images\n",
    "                    y_fake = np.random.uniform(0.7, 1.2, size=(batch_size,))\n",
    "                    aux_y2 = sampled_labels\n",
    "\n",
    "                    # see if the discriminator can figure itself out...\n",
    "                    epoch_disc_loss.append(discriminator.train_on_batch(X_fake, [y_fake, aux_y2]))\n",
    "            # make new noise. we generate Guassian Noise rather than Uniform Noise according to GANHACK\n",
    "            noise = np.random.normal(0, 0.5, (2 * batch_size, latent_size))\n",
    "            sampled_labels = np.random.randint(0, class_num, 2 * batch_size)\n",
    "\n",
    "            # we want to train the generator to trick the discriminator\n",
    "            # For the generator, we want all the {fake, not-fake} labels to say\n",
    "            # not-fake\n",
    "            trick = np.random.uniform(0.7, 1.2, size=(2 * batch_size,))\n",
    "\n",
    "            epoch_gen_loss.append(combined.train_on_batch(\n",
    "                [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n",
    "\n",
    "        print('\\nTesting for epoch {}:'.format(load_epoch))\n",
    "\n",
    "        # evaluate the testing loss here\n",
    "\n",
    "        # generate a new batch of noise\n",
    "        noise = np.random.normal(0, 0.5, (nb_test, latent_size))\n",
    "\n",
    "        # sample some labels from p_c and generate images from them\n",
    "        sampled_labels = np.random.randint(0, class_num, nb_test)\n",
    "        generated_images = generator.predict(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n",
    "\n",
    "        X = np.concatenate((X_test, generated_images))\n",
    "        y = np.array([1] * nb_test + [0] * nb_test)\n",
    "        aux_y = np.concatenate((y_test.reshape(-1, ), sampled_labels), axis=0)\n",
    "\n",
    "        # see if the discriminator can figure itself out...\n",
    "        discriminator_test_loss = discriminator.evaluate(\n",
    "            X, [y, aux_y], verbose=False)\n",
    "\n",
    "        discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
    "\n",
    "        # make new noise\n",
    "        noise = np.random.normal(0, 0.5, (2 * nb_test, latent_size))\n",
    "        sampled_labels = np.random.randint(0, class_num, 2 * nb_test)\n",
    "        trick = np.ones(2 * nb_test)\n",
    "        generator_test_loss = combined.evaluate(\n",
    "            [noise, sampled_labels.reshape((-1, 1))],\n",
    "            [trick, sampled_labels], verbose=False)\n",
    "\n",
    "        generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "\n",
    "        # generate an epoch report on performance\n",
    "        train_history['generator'].append(generator_train_loss)\n",
    "        train_history['discriminator'].append(discriminator_train_loss)\n",
    "\n",
    "        test_history['generator'].append(generator_test_loss)\n",
    "        test_history['discriminator'].append(discriminator_test_loss)\n",
    "\n",
    "        print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format(\n",
    "            'component', *discriminator.metrics_names))\n",
    "        print('-' * 65)\n",
    "\n",
    "        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n",
    "        print(ROW_FMT.format('generator (train)',\n",
    "                             *train_history['generator'][-1]))\n",
    "        print(ROW_FMT.format('generator (test)',\n",
    "                             *test_history['generator'][-1]))\n",
    "        print(ROW_FMT.format('discriminator (train)',\n",
    "                             *train_history['discriminator'][-1]))\n",
    "        print(ROW_FMT.format('discriminator (test)',\n",
    "                             *test_history['discriminator'][-1]))\n",
    "\n",
    "        # save weights every epoch\n",
    "        generator.save_weights(\n",
    "            'params_generator_epoch_{0:03d}.hdf5'.format(load_epoch), True)\n",
    "        discriminator.save_weights(\n",
    "            'params_discriminator_epoch_{0:03d}.hdf5'.format(load_epoch), True)\n",
    "\n",
    "        # generate some pictures to display\n",
    "        noise = np.random.normal(0, 0.5, (100, latent_size))\n",
    "        sampled_labels = np.array([\n",
    "            [i] * 10 for i in range(10)\n",
    "        ]).reshape(-1, 1)\n",
    "        generated_images = generator.predict([noise, sampled_labels]).transpose(0, 2, 3, 1)\n",
    "        generated_images = np.asarray((generated_images * 127.5 + 127.5).astype(np.uint8))\n",
    "\n",
    "\n",
    "        def vis_square(data, padsize=1, padval=0):\n",
    "\n",
    "            # force the number of filters to be square\n",
    "            n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "            padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "            data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "\n",
    "            # tile the filters into an image\n",
    "            data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "            data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "            return data\n",
    "\n",
    "\n",
    "        img = vis_square(generated_images)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        Image.fromarray(img).save(\n",
    "            'images/plot_epoch_{0:03d}_generated.png'.format(load_epoch))\n",
    "\n",
    "        pickle.dump({'train': train_history, 'test': test_history},\n",
    "                        open('acgan-history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
